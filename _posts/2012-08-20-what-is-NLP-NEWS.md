---
layout: post
title: "[스페셜리포트] 자연언어처리(NLP) 무엇인가... 그 기술과 시장은?"
date: 2020-08-20
excerpt: "https://www.aitimes.kr/news/articleView.html?idxno=15036"
tags: [news, nlp]
feature: https://likewind7.github.io/image/nlp_logo.jpg
comments: true
---

출처 : 인공지능 신문 최창현 기자님
<https://www.aitimes.kr/news/articleView.html?idxno=15036>




## 구글 BERT(버트)
 특히 2018년 구글이 공개한 BERT(버트)는 종래보다 우수한 성능을 발휘한다. BERT는 자연언어 처리 태스크를 교육 없이 양방향으로 사전 학습하는 첫 시스템이기 때문이다. '교육 없음'이란 BERT가 보통의 텍스트 말뭉치만을 이용해 훈련되고 있다는 것을 의미한다. 이것은 웹(Web) 상에서 막대한 양의 보통 텍스트 데이터가 여러 언어로 이용 가능하기 때문에 중요한 특징으로 꼽는다. (본지 보도 참조: 인공지능(AI) 언어모델 ‘BERT(버트)'는 무엇인가?)
<http://www.aitimes.kr/news/articleView.html?idxno=13117>


## ETRI 코버트(KorBERT)
지난해 6월 과기정통부의 소프트웨어 분야의 국가 혁신기술 개발형 연구개발 과제인 혁신성장동력 프로젝트로 추진 중인 엑소브레인 사업에서 한국전자통신연구원(ETRI)은 최첨단 한국어 언어모델 ‘코버트(KorBERT)’를 공개했다. 공개한 모델은 두 종류다. 구글의 언어표현 방법을 기반으로 더 많은 한국어 데이터를 넣어 만든 언어모델과 한국어의 ‘교착어’ 특성까지 반영해 만든 언어모델이다.

이 기술은 지난해 3월 한컴오피스 지식검색 베타버전에 탑재되기도 했다.

또 언어처리를 위한 딥러닝 기술을 개발하기 위해서는 텍스트에 기술된 어절을 숫자로 표현해야 한다. 이를 위해 그동안 언어를 활용한 서비스를 개발하는 기관에서는 주로 구글의 다국어 언어모델 버트(BERT)를 사용했다.

버트는 문장 내 어절을 한 글자씩 나눈 뒤, 앞뒤로 자주 만나는 글자끼리 단어로 인식한다. 이 방식은 2017년 11월 처음 공개되었을 때 언어처리 11개 분야에서 많은 성능 향상을 이뤄 주목을 받았다.

그동안 구글은 40여 만 건의 위키백과 문서 데이터를 사용해 한국어 언어모델을 개발해 왔다. ETRI 연구진은 여기에 23기가(GB)에 달하는 지난 10년간의 신문기사와 백과사전 정보를 더해 45억개의 형태소를 학습시켜 구글보다 많은 한국어 데이터를 기반으로 언어모델을 개발했다.

하지만 구글과 ETRI의 언어모델 개발에 활용한 BERT 방식은 현재, 약 512개 이상의 단어가 들어간 문서를 한 번에 처리하지 못한다.

또한 단순히 입력한 데이터양만을 늘리는 것은 언어모델 고도화에 한계가 있다. 아울러, 한글은 다른 언어와 달리 어근에 조사가 붙는 교착어로 한국어의 의미 최소 단위인 형태소까지 고려해 한국어특성을 최대한 반영한 언어모델을 만드는데 심혈을 기울였다.

특히 ETRI는 한국어에 최적화된 언어모델이 '전처리 과정에서 형태소를 분석한 언어모델', '한국어에 최적화된 학습 파라미터', '방대한 데이터 기반' 등이 구글과 차별성 있는 것이 특징이다.

개발된 언어모델은 성능을 확인하는 5가지 기준에서 구글이 배포한 한국어 모델보다 성능이 평균 4.5% 가량 우수했다고 한다. 특히, 단락 순위화(Passage Ranking) 기준에서는 7.4%나 높은 수치를 기록했다.

아울러 지난해 6월 공개된 언어모델을 활용하면 서비스 성능 및 경쟁력을 높일 수 있어 딥러닝 연구, 교육 등의 목적으로 대학, 기업, 기관의 개발자들의 많은 활용이 이루어지고 있다. 개발된 언어모델은 대표적인 딥러닝 프레임워크인 파이토치(PyTorch)와 텐서플로우(Tensorflow) 환경 모두에서 사용 가능하며, 공공인공지능 오픈 API‧데이터 서비스 포털(바로가기)에서 쉽게 찾아볼 수 있다.
<http://aiopen.aihub.or.kr/>


## 카이(khaiii)
카카오는 2018년 말부터 딥러닝 기반 형태소(形態素, morpheme) 분석기 '카이(khaiii)'를 오픈소스로 제공하고 있다. 딥러닝을 통해 학습한 데이터를 활용해 형태소를 분석하는 모델이다. 딥러닝 기술 중 하나인 콘볼루션 신경망(CNN, Convolutional Neural Network)을 이용해 음절기반으로 형태소를 분석하는 방법을 채택했다.

세종 코퍼스를 기반으로 데이터의 오류를 수정하고 카카오에서 자체 구축한 데이터를 추가해 85만 문장, 1003만 어절의 데이터를 학습하여 정확도를 높였다. 또 딥러닝 과정에서 C++ 언어를 적용해 일반적으로 딥러닝에 쓰이는 GPU(그래픽처리장치)를 사용하지 않고도 빠른 분석 속도를 구현했다.

형태소 분석 기술은 2개 이상의 글자로 이루어진 단어 혹은 문장을 입력 시, 의미를 가진 언어 단위 중 가장 작은 단위인 형태소 단위로 자동으로 분리하는 기술이다. 예를 들면, '학교에 간다'라고 입력하면 '학교/명사 + 에/조사 + 가/동사 + ㄴ다/어미' 로 형태소 단위와 품사를 파악해 분류해내는 기술이다.

깃허브(GitHub)에서 확인할 수 있으며, 누구나 무료로 이용 가능하며(깃허브 바로가기), 주로 자연어처리 응용 서비스의 기반 기술로 사용되며, 정보 검색, 기계 번역, 스마트 스피커나 챗봇 등 여러 서비스에서 사용할 수 있다. 

네이버는 업계에서 가장 먼저 선도적으로 NLP의 중요성을 인식하고 개발과 투자로 축적한 기술력과 서비스 노하우를 바탕으로 네이버 검색이 자연어 처리 분야에서 검색 이용자의 의도를 더욱 잘 이해하는 검색으로 진화하고 있다. 


## LG CNS 코쿼드 2.0(KorQuAD 2.0)
지난해 9월 LG CNS는 국내 처음이자 유일하게 AI의 연어 이해를 위한 AI 학습용 표준데이터 ‘코쿼드 2.0(KorQuAD 2.0)’를 공개하고 국내 AI 업계에 무료로 개방했다. ‘코쿼드 2.0’은 한국어 표준데이터를 7만개에서 10만개로 확대하고 단답형에서 장문의 답변이 가능한 AI를 개발할 수 있도록 데이터를 강화한 버전이다.

예를 들어, “대한민국의 수도와 그 면적은?” 이라는 질문에 “서울특별시, 605.25km2 입니다” 라고 답하는 AI는 코쿼드 1.0 학습만으로 충분히 개발 가능했다. 하지만 “서울특별시의 특징은?” 이라는 질문에 “도시 중앙으로 한강이 흐르고 북한산, 관악산, 도봉산 등의 여러 산들로 둘러싸인…” 이라는 장문의 답을 이제, 코쿼드 2.0으로 학습을 통해 가능해진 것이다.

특히 한국어 표준데이터 코쿼드 2.0은 AI가 표나 리스트 형태에 담긴 정보도 읽어 답변할 수 있게끔 표준데이터 범위도 확대했다. 정보 4만건과 질의응답 세트 10만건으로 구성되어 있다. 10만건의 질의응답 세트 중 약 9만건은 AI 학습용으로 사용되고, 1만건은 개발된 AI의 성능 평가용으로 사용된다.

아울러 코쿼드 학습으로 개발된 AI는 코쿼드 홈페이지에 등록해 성능 평가를 받을 수 있으며 리더보드에 등재돼 다른 AI와의 성능 수준을 비교해볼 수도 있다. 성능 평가 결과는 EM(실제 정답과 정확하게 일치하는 비율)과 F1(정답과 유사한 답변을 내놓는 비율) 점수로 나타난다, 사람은 평균 EM(80.17점), F1(91.20점)을 기록한다.

현재 리더보드 1위인 네이버가 코쿼드를 사용해 개발한 AI의경우 EM(86.84점), F1(94.75점)을 기록 중이며, 이는 사람보다 높은 답변 수준임을 나타내고 있는 것이다. 한편, AI의 연어 이해를 위한 AI 학습용 표준데이터는 코쿼드 웹사이트(바로가기)에서 다운로드 받을 수 있으며 누구나 활용 가능하다.  <https://korquad.github.io/>




계속
